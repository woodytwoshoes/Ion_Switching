{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. We can see here that when weights are ignored, the use of ordinal data significantly increases the f1 score. Note that we also get a fairly good f1 score even though we are using a single feature of signal. So let's proceed from now on using ordinal data approach but we'll get some real features to play with (windows etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "5000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "df = pd.read_csv('train.csv',index_col=0);\n",
    "\n",
    "df_terminus = df.index.values[-1]\n",
    "batches = int(df_terminus/50)\n",
    "seconds_in_batch = 50\n",
    "freq = 10000\n",
    "\n",
    "base = np.array([])\n",
    "for batch in range(batches):\n",
    "    mini_array = np.ones(seconds_in_batch*freq)*batch\n",
    "    base = np.append(base,mini_array)\n",
    "\n",
    "df['batch'] = base\n",
    "df['batch'] = df['batch'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to generate some x values which are a little bit more engineered than usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new batch:  0\n",
      "End batch:  0  with padded fraction =  0.002858\n",
      "Starting new batch:  1\n",
      "End batch:  1  with padded fraction =  0.0\n",
      "Starting new batch:  2\n",
      "End batch:  2  with padded fraction =  0.003518\n",
      "Starting new batch:  3\n",
      "End batch:  3  with padded fraction =  0.008\n",
      "Starting new batch:  4\n",
      "End batch:  4  with padded fraction =  0.008\n",
      "Starting new batch:  5\n",
      "End batch:  5  with padded fraction =  0.00448\n",
      "Starting new batch:  6\n",
      "End batch:  6  with padded fraction =  0.004\n",
      "Starting new batch:  7\n",
      "End batch:  7  with padded fraction =  0.004\n",
      "Starting new batch:  8\n",
      "End batch:  8  with padded fraction =  0.004\n",
      "Starting new batch:  9\n",
      "End batch:  9  with padded fraction =  0.004\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "#Set the sample_factor to an integer n which will sample every nth datapoint\n",
    "#This significantly speeds up dataset creation.\n",
    "\n",
    "sample_factor = 100\n",
    "\n",
    "for batch_number in range(batches):\n",
    "    print('Starting new batch: ', batch_number)\n",
    "    window_size = 0.001\n",
    "    indices = df[df.batch == batch_number].index.values\n",
    "    padd_no = 0\n",
    "    for index in indices[::sample_factor]:\n",
    "        \n",
    "        if index % 25 == 0:\n",
    "            print(index)\n",
    "        \n",
    "        open_channels = df.loc[index].open_channels\n",
    "        features = df.loc[index-window_size/2:index+window_size/2].signal.values\n",
    "\n",
    "        if len(features) <= int(window_size*10000):\n",
    "\n",
    "            padding = np.ones((int(window_size*10000)-len(features))+1)*features.mean()\n",
    "            features = np.append(features,padding)\n",
    "            padd_no += 1\n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(open_channels)\n",
    "    print('End batch: ', batch_number, ' with padded fraction = ', padd_no/len(indices))\n",
    "     \n",
    "X = np.array(X)\n",
    "y = np.array(y).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try implementing the ordinal classifier\n",
    "https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "class OrdinalClassifier():\n",
    "    \n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clfs = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.unique_class = np.sort(np.unique(y))\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for i in range(self.unique_class.shape[0]-1):\n",
    "                # for each k - 1 ordinal value we fit a binary classification problem\n",
    "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
    "                clf = clone(self.clf)\n",
    "                clf.fit(X, binary_y)\n",
    "                self.clfs[i] = clf\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        clfs_predict = {k:self.clfs[k].predict_proba(X) for k in self.clfs}\n",
    "        predicted = []\n",
    "        for i,y in enumerate(self.unique_class):\n",
    "            if i == 0:\n",
    "                # V1 = 1 - Pr(y > V1)\n",
    "                predicted.append(1 - clfs_predict[y][:,1])\n",
    "            elif y in clfs_predict:\n",
    "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
    "                 predicted.append(clfs_predict[y-1][:,1] - clfs_predict[y][:,1])\n",
    "            else:\n",
    "                # Vk = Pr(y > Vk-1)\n",
    "                predicted.append(clfs_predict[y-1][:,1])\n",
    "        return np.vstack(predicted).T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a multiclass logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf_ordinal = OrdinalClassifier(clf)\n",
    "clf_ordinal.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ordinal.unique_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for vals_ords w/o weighting is  0.20280004283037076\n"
     ]
    }
   ],
   "source": [
    "preds_val_ord = clf_ordinal.predict(X_val)\n",
    "\n",
    "print('f1 score for vals_ords w/o weighting is ', f1_score(y_val, preds_val_ord, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1 score for vals_ords w/o weighting and just one feature is  0.19297993133718946\n",
    "f1 score for vals_ords w/o weighting and 11 features is  0.20280004283037076\n",
    "\n",
    "That's...not much of an improvement. Quite disappointing really! Maybe the sampling_factor is creating issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new batch:  0\n",
      "End batch:  0  with padded fraction =  0.027982\n",
      "Starting new batch:  1\n",
      "End batch:  1  with padded fraction =  0.0\n",
      "Starting new batch:  2\n",
      "End batch:  2  with padded fraction =  0.036606\n",
      "Starting new batch:  3\n",
      "End batch:  3  with padded fraction =  0.0832\n",
      "Starting new batch:  4\n",
      "End batch:  4  with padded fraction =  0.0832\n",
      "Starting new batch:  5\n",
      "End batch:  5  with padded fraction =  0.046592\n",
      "Starting new batch:  6\n",
      "End batch:  6  with padded fraction =  0.0416\n",
      "Starting new batch:  7\n",
      "End batch:  7  with padded fraction =  0.0416\n",
      "Starting new batch:  8\n",
      "End batch:  8  with padded fraction =  0.0416\n",
      "Starting new batch:  9\n",
      "End batch:  9  with padded fraction =  0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for vals_ords w/o weighting is  0.20227509048786188\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "#Set the sample_factor to an integer n which will sample every nth datapoint\n",
    "#This significantly speeds up dataset creation.\n",
    "\n",
    "sample_factor = 10\n",
    "\n",
    "for batch_number in range(batches):\n",
    "    print('Starting new batch: ', batch_number)\n",
    "    window_size = 0.001\n",
    "    indices = df[df.batch == batch_number].index.values\n",
    "    padd_no = 0\n",
    "    for index in indices[::sample_factor]:\n",
    "        \n",
    "        if index % 25 == 0:\n",
    "            print(index)\n",
    "        \n",
    "        open_channels = df.loc[index].open_channels\n",
    "        features = df.loc[index-window_size/2:index+window_size/2].signal.values\n",
    "\n",
    "        if len(features) <= int(window_size*10000):\n",
    "\n",
    "            padding = np.ones((int(window_size*10000)-len(features))+1)*features.mean()\n",
    "            features = np.append(features,padding)\n",
    "            padd_no += 1\n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(open_channels)\n",
    "    print('End batch: ', batch_number, ' with padded fraction = ', padd_no/len(indices))\n",
    "     \n",
    "X = np.array(X)\n",
    "y = np.array(y).astype('int')\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.20, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf_ordinal = OrdinalClassifier(clf)\n",
    "clf_ordinal.fit(X_train,y_train)\n",
    "\n",
    "preds_val_ord = clf_ordinal.predict(X_val)\n",
    "\n",
    "print('f1 score for vals_ords w/o weighting is ', f1_score(y_val, preds_val_ord, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling at a higher rate did NOT increase our f1 score significantly. At this point, I think I'll make a submission.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700.0\n",
      "500.0001\n",
      "4\n",
      "2000000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv',index_col=0);\n",
    "\n",
    "df_terminus = df_test.index.values[-1]\n",
    "print(df_terminus)\n",
    "df_init = df_test.index.values[0]\n",
    "print(df_init)\n",
    "seconds_in_batch = 50\n",
    "batches = int(round((df_terminus-df_init)/seconds_in_batch))\n",
    "print(batches)\n",
    "\n",
    "freq = 10000\n",
    "\n",
    "base = np.array([])\n",
    "for batch in range(batches):\n",
    "    mini_array = np.ones(seconds_in_batch*freq)*batch\n",
    "    base = np.append(base,mini_array)\n",
    "\n",
    "print(len(base))\n",
    "print(len(df_test))\n",
    "df_test['batch'] = base\n",
    "df_test['batch'] = df_test['batch'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new batch:  0\n",
      "525.0\n",
      "550.0\n",
      "End batch:  0  with padded fraction =  0.257928\n",
      "Starting new batch:  1\n",
      "575.0\n",
      "600.0\n",
      "End batch:  1  with padded fraction =  0.208\n",
      "Starting new batch:  2\n",
      "625.0\n",
      "650.0\n",
      "End batch:  2  with padded fraction =  0.208\n",
      "Starting new batch:  3\n",
      "675.0\n",
      "700.0\n",
      "End batch:  3  with padded fraction =  0.208008\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "\n",
    "#Set the sample_factor to an integer n which will sample every nth datapoint\n",
    "#This significantly speeds up dataset creation.\n",
    "\n",
    "sample_factor = 1\n",
    "\n",
    "for batch_number in range(batches):\n",
    "    print('Starting new batch: ', batch_number)\n",
    "    window_size = 0.001\n",
    "    indices = df_test[df_test.batch == batch_number].index.values\n",
    "    padd_no = 0\n",
    "    for index in indices[::sample_factor]:\n",
    "        \n",
    "        if index % 25 == 0:\n",
    "            print(index)\n",
    "        \n",
    "        features = df_test.loc[index-window_size/2:index+window_size/2].signal.values\n",
    "\n",
    "        if len(features) <= int(window_size*10000):\n",
    "\n",
    "            padding = np.ones((int(window_size*10000)-len(features))+1)*features.mean()\n",
    "            features = np.append(features,padding)\n",
    "            padd_no += 1\n",
    "            \n",
    "        X.append(features)\n",
    "    print('End batch: ', batch_number, ' with padded fraction = ', padd_no/len(indices))\n",
    "     \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_ord = clf_ordinal.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_test_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['open_channels'] = preds_test_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_sample = pd.read_csv('sample_submission.csv',index_col=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_channels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0002</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0005</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          open_channels\n",
       "time                   \n",
       "500.0001              0\n",
       "500.0002              0\n",
       "500.0003              0\n",
       "500.0004              0\n",
       "500.0005              0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()\n",
    "df_test['time'] = df_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = df_test[['time','open_channels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('submissionV5.csv',index=False,float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_read = pd.read_csv('submissionV5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open_channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  open_channels\n",
       "0  500.0001              0\n",
       "1  500.0002              0\n",
       "2  500.0003              0\n",
       "3  500.0004              0\n",
       "4  500.0005              0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ubuntu/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 21.0M/21.0M [00:00<00:00, 33.7MB/s]\n",
      "Successfully submitted to University of Liverpool - Ion Switching"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c liverpool-ion-switching -f submissionV5.csv -m \"index false, 3fig, logreg ordinal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
